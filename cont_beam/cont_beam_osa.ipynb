{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cantilever beam physics-informed neural network (PINN)\n",
    "\n",
    "## Problem overview\n",
    "\n",
    "The example problem we solve here is a continuous beam:\n",
    "$$ \\rho A \\frac{\\partial^2w}{\\partial t^2} + E I \\frac{\\partial^4w}{\\partial x^4} + \\rho A c \\frac{\\partial w}{\\partial t} = f(t) $$\n",
    "$$ w(x, t) = \\sum_{j=1}^{\\infty}\\varphi_j(x)q_j(t) \\approx \\sum_{j=1}^{n}\\varphi_j(x)q_j(t) $$\n",
    "where $\\varphi_j$ and $q_j$ are the $j^{th}$ modal shape and coordinate of the $j^{th}$ mode, respectively.\n",
    "$$\n",
    "\\mathbf{M}\\ddot{\\mathbf{q}}(t) + \\mathbf{C}\\dot{\\mathbf{q}}(t) + \\mathbf{K}\\mathbf{q}(t) = \\mathbf{S_p}\\mathbf{p}(t)\n",
    "$$\n",
    "where,\n",
    "$$\n",
    "\\mathbf{M} = \\rho A \\int_0^l\\mathbf{\\psi}(x)\\mathbf{\\psi}^T(x) dx, \\qquad\n",
    "\\mathbf{C} = \\rho Ac \\int_0^l\\mathbf{\\psi}(x)\\mathbf{\\psi}^T(x) dx, \\qquad\n",
    "\\mathbf{K} = EI \\int_0^l\\mathbf{\\psi}(x){\\mathbf{\\psi}''''}^T(x) dx\n",
    "$$\n",
    "in the state space,\n",
    "$$\n",
    "\\dot{\\mathbf{\\tau}}(t) = \\mathbf{A} \\mathbf{\\tau}(t) + \\mathbf{H} \\mathbf{f}(t)\n",
    "$$\n",
    "where,\n",
    "$$\n",
    "\\mathbf{\\tau} = \\begin{bmatrix} \\mathbf{q}(t) \\\\ \\dot{\\mathbf{q}}(t) \\end{bmatrix}, \\qquad\n",
    "\\mathbf{A} = \\begin{bmatrix} 0 & \\mathbf{I} \\\\ -\\mathbf{M}^{-1}\\mathbf{K} & -\\mathbf{M}^{-1}\\mathbf{C} \\end{bmatrix}, \\qquad\n",
    "\\mathbf{H} = \\begin{bmatrix} 0 \\\\ \\mathbf{M}^{-1} \\end{bmatrix}, \\qquad\n",
    "\\mathbf{f}(t) = m_e g\\mathbf{\\Psi}(x_e)\\mathbf{I}\n",
    "$$\n",
    "And the measurement vector is,\n",
    "$$ \\mathbf{y}(t) = \\begin{bmatrix} S_d & 0 \\\\ 0 & S_a \\end{bmatrix} \\begin{bmatrix} \\mathbf{q}(t) \\\\ \\ddot{\\mathbf{q}}(t) \\end{bmatrix} $$\n",
    "\n",
    "<!-- $$\n",
    "\\mathrm{argmin}\\mathcal{L}(\\mathbf{x},t;\\mathbf{\\theta}) := \\mathcal{L}_a + \\lambda\\left[ \\mathcal{L}_{ode} \\right]\n",
    "$$\n",
    "$$\n",
    "\\mathcal{L}_a = \\langle \\varphi_{kj}\\hat{q}_j - y_k^* \\rangle\n",
    "$$\n",
    "$$\n",
    "\\mathcal{L}_{ode,j} = \\langle \\hat{\\ddot{q}}_j + 2\\hat{\\zeta}\\hat{\\omega}_j\\hat{\\dot{q}}_j + \\hat{\\omega}^2\\hat{q}_j - p^*_j \\rangle, \\qquad\n",
    "\\mathcal{L}_{ode,j} = \\langle \\hat{m} \\partial^2_{\\hat{t}}\\mathcal{N}_{\\hat{q}} + \\hat{c} \\partial_{\\hat{t}}\\mathcal{N}_{\\hat{x}} + \\hat{k}\\mathcal{N}_{\\hat{x}} \\rangle _{\\Omega_d}\n",
    "$$\n",
    "where,\n",
    "$$ \\mathcal{N}_{\\bullet} = \\mathcal{N}_{\\bullet}(\\mathbf{x};\\mathbf{\\theta}), \\qquad \n",
    "\\partial_{*}\\bullet = \\frac{\\partial\\bullet}{\\partial *}, \\qquad \n",
    "\\partial^2_{*}\\bullet = \\frac{\\partial^2\\bullet}{\\partial *^2}, \\qquad\n",
    "\\langle\\bullet\\rangle _{\\Omega_{\\kappa}} = \\frac{1}{N_{\\kappa}}\\sum_{x\\in\\Omega_{\\kappa}}\\left|\\left|\\bullet\\right|\\right|^2 $$\n",
    "\n",
    "ODE loss function comes from including the normalisation of the parameters, then choosing the suitable range to aid optimisation.\n",
    "\n",
    "$$\n",
    "\\frac{1}{\\alpha_t^2} \\partial^2_{\\hat{t}}\\hat{q} + \\tilde{c}\\frac{1}{\\alpha_t}\\partial_{\\hat{t}}\\hat{q} + \\tilde{k} \\hat{q} = 0, \\qquad \\hat{m} \\partial^2_{\\hat{t}}\\hat{q} + \\hat{c} \\partial_{\\hat{t}}\\hat{q} + \\hat{k}\\hat{q} = 0\n",
    "$$\n",
    "> trad(itional)\n",
    "$$\n",
    "\\hat{m} = \\frac{1}{\\alpha_t^2}, \\quad \\hat{c} = \\tilde{c}\\frac{1}{\\alpha_t}, \\quad \\hat{k} = \\tilde{k}\n",
    "$$\n",
    "> up_time\n",
    "$$\n",
    "\\hat{m} = \\frac{1}{\\alpha_t}, \\quad \\hat{c} = \\tilde{c}, \\quad \\hat{k} = \\tilde{k}\\alpha_t\n",
    "$$\n",
    "> up_time2\n",
    "$$\n",
    "\\hat{m} = 1, \\quad \\hat{c} = \\tilde{c}\\alpha_t, \\quad \\hat{k} = \\tilde{k}\\alpha_t^2\n",
    "$$ -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osa_beam_pinn import osa_pinn_beam, osa_pinn_beam_v1_2, normalise\n",
    "from beam_solutions import cont_beam\n",
    "from math import pi\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm as tqdma\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_beam_params(E, rho, EI, pA):\n",
    "    I_ = EI/E\n",
    "    A_ = pA/rho\n",
    "    h = (2*I_/A_)**(0.5)\n",
    "    b = A_/h\n",
    "    I = (1/12) * b * h**3\n",
    "    A = b * h\n",
    "    return I, A, b, h\n",
    "\n",
    "def plot_vib_surface(ax, x, time, w, sub_samp=10):\n",
    "    if len(x.shape) == 1 and len(time.shape) == 1:\n",
    "        xx, tt = torch.meshgrid(x[::sub_samp], time[::sub_samp], indexing=\"ij\")\n",
    "        x_ = unroll_mat(xx)\n",
    "        time_ = unroll_mat(tt)\n",
    "    else:\n",
    "        if x.shape[1] > 1 and time.shape[1] > 1:\n",
    "            x_ = unroll_mat(x[::sub_samp,:][:,::sub_samp])\n",
    "            time_ = unroll_mat(time[::sub_samp,:][:,::sub_samp])\n",
    "        elif x.shape[1] <= 1 and time.shape[1] <= 1:\n",
    "            xx, tt = torch.meshgrid(x[::sub_samp], time[::sub_samp], indexing=\"ij\")\n",
    "            x_ = unroll_mat(xx)\n",
    "            time_ = unroll_mat(tt)\n",
    "    if len(w.shape) == 1:\n",
    "        w_ = w[::sub_samp]\n",
    "    else:\n",
    "        if w.shape[1] > 1:\n",
    "            w_ = unroll_mat(w[::sub_samp,:][:,::sub_samp])\n",
    "        else:\n",
    "            w_ = w[::sub_samp]\n",
    "\n",
    "    ax.plot_trisurf(x_, time_, w_, cmap=cm.plasma, linewidth=0.1, edgecolor='black')\n",
    "    ax.set_xlabel('x, m')\n",
    "    ax.set_ylabel('Time, s')\n",
    "    ax.set_zlabel('w, m')\n",
    "\n",
    "def plot_vib_scatter(ax, x, time, w, color='grey'):\n",
    "    ax.scatter3D(x, time, w, color=color)\n",
    "    ax.set_xlabel('x, m')\n",
    "    ax.set_ylabel('Time, s')\n",
    "    ax.set_zlabel('w, m')\n",
    "\n",
    "def unroll_mat(data):\n",
    "    nn = data.shape[0]*data.shape[1]\n",
    "    data_ = torch.zeros(nn)\n",
    "    di = 0\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            data_[di] = data[i,j]\n",
    "            di += 1\n",
    "    return data_\n",
    "\n",
    "def roll_mat(data, n1, n2):\n",
    "    data_ = torch.zeros((n1, n2))\n",
    "    d_count = 0\n",
    "    for i in range(n1):\n",
    "        for j in range(n2):\n",
    "            data_[i, j] = data[d_count]\n",
    "            d_count += 1\n",
    "    return data_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the analytical solution over the full domain\n",
    "E = 1e7\n",
    "rho = 2700\n",
    "EI_ = 5e-3\n",
    "pA = 1.0\n",
    "c = 0.0\n",
    "l = 1.0\n",
    "w1 = (pi**2) * ((EI_)/(pA*(l**4)))**0.5\n",
    "f1 = w1/(2*pi)\n",
    "I, A, b, h = gen_beam_params(E, rho, EI_, pA)\n",
    "\n",
    "nx = 128\n",
    "nt = 64\n",
    "n_modes = 6\n",
    "\n",
    "beam_kwargs_sep = {\n",
    "    \"E\" : E,\n",
    "    \"I\" : I,\n",
    "    \"rho\" : rho,\n",
    "    \"A\" : A,\n",
    "    \"l\" : l\n",
    "}\n",
    "\n",
    "beam_kwargs_cmb = {\n",
    "    \"EI\" : EI_,\n",
    "    \"pA\" : pA,\n",
    "    \"l\" : l\n",
    "}\n",
    "\n",
    "# ss_beam = cont_beam(\"sep_vars\", beam_kwargs_sep)\n",
    "ss_beam = cont_beam(\"cmb_vars\", **beam_kwargs_cmb)\n",
    "ss_beam.gen_modes(\"ss-ss\", n_modes, nx)\n",
    "\n",
    "xx = ss_beam.xx\n",
    "\n",
    "fig, axs = plt.subplots(4, 1, figsize=(12,12))\n",
    "for i in range(4):\n",
    "    axs[i].plot(xx, ss_beam.phi_n[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = 1\n",
    "init_disp = 0.1\n",
    "v0 = 0.0\n",
    "vv0 = torch.zeros(nx)\n",
    "\n",
    "t = torch.linspace(0,2.5,nt)\n",
    "\n",
    "# init_load = {\n",
    "#     \"type\" : \"point_load\",\n",
    "#     \"f0\" : f0,\n",
    "#     \"load_coord\" : 0.1,\n",
    "# }\n",
    "# w0 = ss_beam.init_cond_load(init_load)\n",
    "# wxt, wxt_n = ss_beam.free_vibration(t, w0, vv0, 0.0)\n",
    "\n",
    "# forcing = {\n",
    "#     \"type\" : \"step_load\",\n",
    "#     \"force_mag\" : f0,\n",
    "#     \"load_coord\" : 0.1\n",
    "# }\n",
    "# forcing = {\n",
    "#     \"type\" : \"harmonic\",\n",
    "#     \"force_mag\" : f0,\n",
    "#     \"load_coord\" : 0.1,\n",
    "#     \"frequency\" : 0.8\n",
    "# }\n",
    "# wxt, wxt_n = ss_beam.forced_vibration(t, forcing)\n",
    "\n",
    "# init_disp_loc = 0.1\n",
    "# init_disp_id = torch.argmin(torch.abs(ss_beam.xx - init_disp_loc))\n",
    "# w0 = torch.zeros(nx)\n",
    "# w0[init_disp_id] = init_disp\n",
    "w0_func = lambda x : init_disp * torch.sin(3*pi*x)\n",
    "w0 = w0_func(ss_beam.xx)\n",
    "# wxt, wxtd, wxtdd, wxt_n = ss_beam.free_vibration(t, w0, vv0)\n",
    "\n",
    "xx_g, tt = torch.meshgrid((ss_beam.xx, t), indexing=\"ij\")\n",
    "omega3 = 9*(pi**2) * (EI_/pA)**(0.5)\n",
    "wxt = init_disp * torch.sin(3*pi*xx_g)*torch.cos(omega3*tt)\n",
    "wxtd = init_disp * -omega3*torch.sin(3*pi*xx_g)*torch.sin(omega3*tt)\n",
    "wxtdd = init_disp * -(omega3**2)*torch.sin(3*pi*xx_g)*torch.cos(omega3*tt)\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(8,6))\n",
    "axs[0].plot(xx, w0)\n",
    "axs[1].plot(xx, wxt[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sens = 10\n",
    "sens_distance = xx[-1]/(n_sens+1)  # distance between sensors\n",
    "s_locs = np.arange(sens_distance, xx[-1], sens_distance)  # target location of sensors\n",
    "s_ids = [np.argmin(np.abs(xx - s_locs[i])) for i in range(n_sens)]\n",
    "# s_ids = s_ids[:-int(n_sens/2)]\n",
    "\n",
    "plot_locs = [0.3, 0.45, 0.80]  # target location for plotting\n",
    "plot_ids_ss = [np.argmin(np.abs(xx[np.array(s_ids)] - plot_locs[i])) for i in range(3)]  # plotting location ids, relative to sensor dataset\n",
    "plot_locs_ = [xx[s_ids[k]] for k in plot_ids_ss]\n",
    "plot_ids_gt = [np.argmin(np.abs(xx - plot_locs_[i])) for i in range(3)]  # plotting location ids, relative to gt dataset, by taking closest of sensor dataset\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize = (12,8))\n",
    "for i in range(3):\n",
    "    axs[i,0].plot(t, wxt[s_ids[i],:])\n",
    "    axs[i,1].plot(t, wxtd[s_ids[i],:])\n",
    "    axs[i,2].plot(t, wxtdd[s_ids[i],:])\n",
    "axs[0,0].set_title('Displacement')\n",
    "axs[0,1].set_title('Velocity')\n",
    "axs[0,2].set_title('Acceleration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, subplot_kw = {\"projection\":\"3d\"}, figsize=(12,12))\n",
    "axs = axs.ravel()\n",
    "plot_vib_surface(axs[0], xx, t, wxt, 1)\n",
    "plot_vib_surface(axs[1], xx, t, wxtd, 1)\n",
    "plot_vib_surface(axs[2], xx, t, wxtdd, 1)\n",
    "# plot_vib_surface(axs[3], xx, t, wxt_n[:,:,2], 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_hat, alpha_t = normalise(t, \"range\")\n",
    "x_hat, alpha_x = normalise(xx, \"range\")\n",
    "w_hat, alpha_w = normalise(wxt, \"range\", \"all\")\n",
    "wdd_hat, alpha_wdd = normalise(wxtdd, \"range\", \"all\")\n",
    "\n",
    "alphas = {\n",
    "    \"x\" : alpha_x,\n",
    "    \"t\" : alpha_t,\n",
    "    \"w\" : alpha_w,\n",
    "    \"wdd\" : alpha_wdd,\n",
    "    \"pA\" : pA*10,\n",
    "    \"EI\" : EI_*10\n",
    "}\n",
    "\n",
    "ground_truth = {\n",
    "    \"w_hat\" : w_hat,\n",
    "    \"x_hat\" : x_hat,\n",
    "    \"t_hat\" : t_hat\n",
    "}\n",
    "\n",
    "sub_ind_x = torch.tensor(s_ids)  # indices for sub-selection along x (sensor data)\n",
    "sub_ind_t = np.arange(0, int(nt/2), 2)  # indices for sub-selection along time\n",
    "\n",
    "x_data_vec = x_hat[sub_ind_x]  # vector of x data of sensors (observations)\n",
    "L = x_data_vec[1] - x_data_vec[0]\n",
    "\n",
    "t_data_vec = t_hat[sub_ind_t]  # vector of time data of sensors (observations)\n",
    "T_hat = t_data_vec[1] - t_data_vec[0]  # horizon window (normalised)\n",
    "T = T_hat * alpha_t  # horizon window (unnormalised)\n",
    "\n",
    "w_data_mat = w_hat[:, sub_ind_t][sub_ind_x, :]\n",
    "wdd_data_mat = wdd_hat[:, sub_ind_t][sub_ind_x, :]\n",
    "\n",
    "data = {\n",
    "    \"w_hat\" : w_data_mat,\n",
    "    \"x_hat\" : x_data_vec,\n",
    "    \"t_hat\" : t_data_vec\n",
    "}\n",
    "\n",
    "sens_ids_ = [torch.argmin(torch.abs(x_data_vec - s_locs[i]/alpha_x)) for i in range(3)]\n",
    "\n",
    "x_data = x_data_vec.view(-1,1).repeat(1,t_data_vec.shape[0])\n",
    "t_data = t_data_vec.view(-1,1).repeat(1,x_data_vec.shape[0]).T\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, subplot_kw = {\"projection\":\"3d\", \"proj_type\":\"ortho\"}, figsize=(12,12))\n",
    "plot_vib_surface(axs[0], x_hat, t_hat, w_hat, 1)\n",
    "\n",
    "# plot_vib_surface(axs[1], x_data_vec, t_data_vec, w_data_mat, 1)\n",
    "plot_vib_scatter(axs[1], x_data, t_data, w_data_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nn_update(axs_m, ground_truth, data, prediction, alphas):\n",
    "    axs = [axs_m[\"A\"], axs_m[\"B\"], axs_m[\"C\"]]\n",
    "    for ax in axs:\n",
    "        ax.cla()\n",
    "    xL = torch.amax(t_hat)*alphas[\"t\"]\n",
    "    for i in range(3):\n",
    "        axs[i].plot(ground_truth[\"t_hat\"]*alphas[\"t\"], ground_truth[\"w_hat\"][s_ids[i],:]*alphas[\"w\"], color=\"grey\", linewidth=1.5, alpha=0.8, label=\"Ground Truth\")\n",
    "        axs[i].plot(prediction[\"t_hat\"]*alphas[\"t\"], prediction[\"w_hat\"][plot_ids_pred[i],:]*alphas[\"w\"], color=\"tab:blue\", linewidth=1, alpha=0.8, label=\"Neural network prediction\")\n",
    "        axs[i].scatter(data[\"t_hat\"]*alphas[\"t\"], data[\"w_hat\"][i,:]*alphas[\"w\"], s=60, color=\"tab:orange\", alpha=0.4, label='Training data')\n",
    "        yL = torch.amax(torch.abs(ground_truth[\"w_hat\"][s_ids[i],:]))*alphas[\"w\"]\n",
    "        axs[i].set_xlim(-0.05*xL, 1.05*xL)\n",
    "        axs[i].set_ylim(-1.1*yL, 1.1*yL)\n",
    "        axs[i].legend()\n",
    "    axs_m['E'].cla()\n",
    "    plot_vib_surface(axs_m['E'], prediction[\"x_hat\"]*alphas[\"x\"], prediction[\"t_hat\"]*alphas[\"t\"], prediction[\"w_hat\"]*alphas[\"w\"], 1)\n",
    "    plot_vib_scatter(axs_m['E'], x_data*alphas[\"x\"], t_data*alphas[\"t\"], w_data_mat*alphas[\"w\"])\n",
    "\n",
    "def plot_loss_hist(ax,loss_hist):\n",
    "    n_epoch = len(loss_hist)\n",
    "    ax.cla()\n",
    "    loss_labs = ['Observation loss', 'Physics loss', 'TIC loss', 'IC loss', 'Total loss']\n",
    "    loss_cols = ['b', 'r', 'g', 'm', 'k']\n",
    "    for i in range(loss_hist.shape[1]):\n",
    "        ax.plot(np.arange(1,n_epoch+1), loss_hist[:,i], loss_cols[i], label=loss_labs[i])\n",
    "    ax.set_yscale('log')\n",
    "    # ax.set_ylim((1e-2,1e4))\n",
    "    ax.legend()\n",
    "\n",
    "def print_inter():\n",
    "\n",
    "    wpred_vec = beam_osa_model.predict().detach()\n",
    "\n",
    "    wpred = wpred_vec.reshape(beam_osa_model.n_col_x, beam_osa_model.n_col_t)\n",
    "    prediction[\"w_hat\"] = wpred\n",
    "\n",
    "    plot_nn_update(axs, ground_truth, data, prediction, alphas)\n",
    "\n",
    "    plot_loss_hist(axs[\"D\"],np.array(loss_hist))\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    match beam_osa_model.param_type:\n",
    "        case \"constant\":\n",
    "            tqdma.write(\"Epoch : %d ---- Loss: %.2e\" % (i+1,loss_hist[i][-1]))\n",
    "        case \"variable\":\n",
    "            tqdma.write(\"Epoch : %d ---- Loss: %.2e \\npA: %.4f ---- EI: %.4f\" % (i+1, loss_hist[i][-1], beam_osa_model.params[0]*alphas['pA'], beam_osa_model.params[1]*alphas['EI']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PINN\n",
    "Some shorthand definitions,\n",
    "$$ \\mathcal{N}_{\\bullet} = \\mathcal{N}_{\\bullet}(\\mathbf{x};\\mathbf{\\theta}), \\qquad \n",
    "\\partial_{*}\\bullet = \\frac{\\partial\\bullet}{\\partial *}, \\qquad \n",
    "\\partial^n_{*}\\bullet = \\frac{\\partial^n\\bullet}{\\partial *^2}, \\qquad\n",
    "\\langle\\bullet\\rangle _{\\Omega_{\\kappa}} = \\frac{1}{N_{\\kappa}}\\sum_{x\\in\\Omega_{\\kappa}}\\left|\\left|\\bullet\\right|\\right|^2 $$\n",
    "\n",
    "Defined as function of initial displacement, velocity, location, and time:\n",
    "$$\n",
    "\\mathbf{x} = \\{x, t, w_0, \\ddot{w}_0\\} \\quad \\rightarrow \\quad \\mathcal{N}(x, t, w_0, \\ddot{w}_0;\\mathbf{\\theta})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathrm{argmin}L(\\mathbf{x},t;\\mathbf{\\theta}) := \\lambda_0L_{obs} + \\lambda_1 L_{bc} + \\lambda_2 L_{ic} + \\lambda_3 L_{pde}\n",
    "$$\n",
    "Observations:\n",
    "$$\n",
    "L_{obs} = \\langle \\hat{w} - \\mathcal{N}_w \\rangle _{\\Omega_{t=T}}\n",
    "$$\n",
    "Boundary conditions:\n",
    "$$\n",
    "L_{bc} = \\langle \\mathcal{N}_w \\rangle _{\\Omega_{bc}}, \\qquad \\Omega_{bc} \\in x=\\{0.0,l\\}\n",
    "$$\n",
    "Initial conditions:\n",
    "$$\n",
    "L_{ic} = \\left[ \\langle \\ddot{w}_0 - \\partial^2_t\\mathcal{N}_{w} \\rangle + \\langle w_0 - \\mathcal{N}_{w} \\rangle\\right]_{\\Omega_{t=0}}\n",
    "$$\n",
    "Partial differential equation:\n",
    "$$\n",
    "L_{pde} = \\langle \\rho A \\partial_t^2 \\mathcal{N}_w + EI \\partial_x^4\\mathcal{N}_w \\rangle _{\\Omega_d}, \\qquad \\Omega_d \\in x=0,...,T\n",
    "% \\qquad\n",
    "% L_{pde} = \\langle \\hat{m} \\partial_t^2 \\mathcal{N}_w + \\hat{k} \\partial_x^4\\mathcal{N}_w \\rangle\n",
    "$$\n",
    "\n",
    "ODE loss function comes from including the normalisation of the parameters, then choosing the suitable range to aid optimisation.\n",
    "$$\n",
    "\\frac{\\rho A}{\\alpha_t^2} \\partial^2_{\\hat{t}}\\hat{w} + \\frac{EI}{\\alpha_x^4} \\partial_{\\hat{x}}^4 \\hat{w} = 0, \\quad \\rightarrow \\quad \n",
    "\\hat{m} \\partial^2_{\\hat{t}}\\hat{w} + \\hat{k}\\partial_{\\hat{x}}^4\\hat{w} = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{m} = \\frac{\\rho A}{\\alpha_t^2}, \\quad \\hat{k} = \\frac{EI}{\\alpha_x^4}\n",
    "$$\n",
    "\n",
    "To scale loss function in a physically meaningful way, multiply $\\hat{m}$, $\\hat{c}$, and $\\hat{k}$ by any (or combination) of the following:\n",
    "$$\n",
    "\\Lambda = \\alpha_t,~~\\alpha_t^2,~~\\alpha_x,~~\\alpha_x^2,~~\\alpha_x^3,~~\\alpha_x^4\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "osa_config = {\n",
    "    \"n_input\" : 4,\n",
    "    \"n_output\" : 1,\n",
    "    \"n_hidden\" : 32,\n",
    "    \"n_layers\" : 4,\n",
    "    \"l\" : l,\n",
    "    \"L\" : L,\n",
    "    \"ncx\" : 8,\n",
    "    \"T\" : T,\n",
    "    \"T_hat\" : T_hat,\n",
    "    \"nct\" : 8,\n",
    "    \"phys_params\" : {\n",
    "        \"par_type\" : \"constant\",\n",
    "        \"pA\" : pA,\n",
    "        \"EI\" : EI_\n",
    "    },\n",
    "    \"alphas\" : alphas,\n",
    "    \"pde_norm_Lambda\" : 1.0,\n",
    "    \"ic_func\" : w0_func\n",
    "}\n",
    "\n",
    "# configure PINN\n",
    "beam_osa_model = osa_pinn_beam_v1_2(osa_config)\n",
    "x_pred, t_pred = beam_osa_model.set_colls_and_obs(t_data, x_data, w_data_mat, wdd_data_mat)\n",
    "prediction = {\n",
    "    \"x_hat\" : x_pred[:,0],\n",
    "    \"t_hat\" : t_pred[0,:]\n",
    "}\n",
    "plot_ids_pred = []\n",
    "for i in range(len(s_ids)):\n",
    "    plot_id1 = torch.argwhere(x_pred[:,0]==xx[s_ids[i]])\n",
    "    plot_ids_pred.append(plot_id1[-1].item())\n",
    "# plot_ids_pred = torch.argwhere()\n",
    "\n",
    "# beam_osa_model = beam_osa_model.to(device)\n",
    "\n",
    "# configure optimiser\n",
    "epochs = int(500e3)\n",
    "learning_rate = 1e-3\n",
    "betas = (0.95,0.999)\n",
    "optimizer = torch.optim.Adam(beam_osa_model.parameters(), lr=learning_rate, betas=betas)\n",
    "\n",
    "# epochs = int(50e3)\n",
    "# learning_rate = 5e-3\n",
    "# optimizer = torch.optim.LBFGS(beam_osa_model.parameters(), lr=learning_rate, max_eval=20)\n",
    "\n",
    "lambds = {\n",
    "    'obs' : 100.0,\n",
    "    'bc' : 0.0,\n",
    "    'ic' : 6.0,\n",
    "    'tic' : 100.0,\n",
    "    'pde' : 0.001,\n",
    "    # 'cc' : [1e-6, 1e-6],\n",
    "    'cc' : [0.0, 0.0]\n",
    "    }\n",
    "\n",
    "fig, axs = plt.subplot_mosaic(\n",
    "    \"AD;BE;CE\",\n",
    "    per_subplot_kw = {\n",
    "    \"E\" : {\"projection\" : \"3d\"}\n",
    "    },\n",
    "    figsize=(18,12), \n",
    "    facecolor='w'\n",
    "    )\n",
    "loss_hist=[]\n",
    "print_step = 100\n",
    "beam_osa_model.set_loss_switches(lambds)\n",
    "\n",
    "for i in tqdm(range(epochs)):\n",
    "\n",
    "    # def closure():\n",
    "    #     optimizer.zero_grad()\n",
    "    #     loss, losses = beam_osa_model.loss_func(lambds)\n",
    "    #     loss_hist.append([loss_it.item() for loss_it in losses] + [loss.item()])\n",
    "    #     loss.backward()\n",
    "    #     return loss\n",
    "    \n",
    "    # optimizer.step(closure)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss, losses = beam_osa_model.loss_func(lambds)\n",
    "    loss_hist.append([loss_it.item() for loss_it in losses] + [loss.item()])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (i+1) % print_step == 0:\n",
    "        print_inter()\n",
    "\n",
    "display.clear_output()\n",
    "match beam_osa_model.param_type:\n",
    "    case \"constant\":\n",
    "        tqdma.write(\"Epoch : %d ---- Loss: %.2e\" % (i+1,loss_hist[i][-1]))\n",
    "    case \"variable\":\n",
    "        tqdma.write(\"Epoch : %d ---- Loss: %.2e \\npA: %.4f ---- EI: %.4f\" % (i+1, loss_hist[i][-1], beam_osa_model.params[0]*alphas['pA'], beam_osa_model.params[1]*alphas['EI']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
